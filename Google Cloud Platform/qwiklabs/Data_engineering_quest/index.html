
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
      
        <link rel="prev" href="../BigQuery%20for%20data%20warehousing/">
      
      
        <link rel="next" href="../Machine%20learning%20APIs/">
      
      
      <link rel="icon" href="../../../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.5.3, mkdocs-material-9.5.4">
    
    
      
        <title>Data Engineering Quest - Road to a data engineer</title>
      
    
    
      <link rel="stylesheet" href="../../../assets/stylesheets/main.50c56a3b.min.css">
      
        
        <link rel="stylesheet" href="../../../assets/stylesheets/palette.06af60db.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Ubuntu:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Ubuntu";--md-code-font:"Roboto Mono"}</style>
      
    
    
      <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.7.2/styles/default.min.css">
    
    <script>__md_scope=new URL("../../..",location),__md_hash=e=>[...e].reduce((e,_)=>(e<<5)-e+_.charCodeAt(0),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="black" data-md-color-accent="cyan">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#data-engineering-quest" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../../.." title="Road to a data engineer" class="md-header__button md-logo" aria-label="Road to a data engineer" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54Z"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2Z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            Road to a data engineer
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Data Engineering Quest
            
          </span>
        </div>
      </div>
    </div>
    
      
    
    
    
    
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    



<nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../../.." title="Road to a data engineer" class="md-nav__button md-logo" aria-label="Road to a data engineer" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54Z"/></svg>

    </a>
    Road to a data engineer
  </label>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../.." class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Current situation and learning path
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Data%20Engineer%20Landscape/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Data Engineering Landscape
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3" >
        
          
          <label class="md-nav__link" for="__nav_3" id="__nav_3_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Databases
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3">
            <span class="md-nav__icon md-icon"></span>
            Databases
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Databases/Data%20Warehouse%20Toolkit/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Data warehouse toolkit notes
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Databases/Database_design/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Database Design video course and notes
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4" >
        
          
          <label class="md-nav__link" for="__nav_4" id="__nav_4_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Decision Journal
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_4">
            <span class="md-nav__icon md-icon"></span>
            Decision Journal
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Decision%20Journal/01%20GCP%20decision/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Decision: Choice of cloud platform to learn
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Decision%20Journal/dj%20template/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Decision Journal Template
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
    
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5" checked>
        
          
          <label class="md-nav__link" for="__nav_5" id="__nav_5_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Google Cloud Platform
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_5_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_5">
            <span class="md-nav__icon md-icon"></span>
            Google Cloud Platform
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../GCP%20code%20snippets/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Common GCP code snippets
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5_2" >
        
          
          <label class="md-nav__link" for="__nav_5_2" id="__nav_5_2_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Data Engineering Certificate
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_5_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5_2">
            <span class="md-nav__icon md-icon"></span>
            Data Engineering Certificate
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../Data%20Engineering%20Certificate/de_certificate_misc_notes/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Data Engineering Certificate Misc Notes
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../Data%20Engineering%20Certificate/de_certificate_practice_exam_notes/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Data Engineering practice Exam notes
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../Data%20Engineering%20Certificate/google_ai_platform/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Google AI Platform
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../Data%20Engineering%20Certificate/google_bigquery/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    BigQuery
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../Data%20Engineering%20Certificate/google_bigtable/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Google Cloud Bigtable
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../Data%20Engineering%20Certificate/google_cloud_sql/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Cloud SQL
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../Data%20Engineering%20Certificate/google_dataflow/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Google Dataflow
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../Data%20Engineering%20Certificate/google_datalab/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Google Datalab
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../Data%20Engineering%20Certificate/google_dataproc/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Google Dataproc
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../Data%20Engineering%20Certificate/google_datastore_and_firestore/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Google Datastore and Firestore
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../Data%20Engineering%20Certificate/google_memorystore/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Google Memorystore
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../Data%20Engineering%20Certificate/google_pubsub/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Google Pub/Sub
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../Data%20Engineering%20Certificate/google_spanner/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Google Cloud Spanner
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../Data%20Engineering%20Certificate/google_storage/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Google Storage
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../Data%20Engineering%20Certificate/google_tensorflow/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Google Tensorflow
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
    
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5_3" checked>
        
          
          <label class="md-nav__link" for="__nav_5_3" id="__nav_5_3_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Qwiklabs
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_5_3_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_5_3">
            <span class="md-nav__icon md-icon"></span>
            Qwiklabs
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../01_Quest%20badges/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Badges earned on Qwiklabs
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Baseline%20Data%20ML%20AI%20quest/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Baseline Data ML AI Quest
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Baseline%20Infrasctructure/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Baseline Infrastructure Quest
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../BigQuery%20for%20Data%20Analysts/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    BigQuery for data analysts quest
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../BigQuery%20for%20Marketing/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    BigQuery for Marketing Analysts
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../BigQuery%20for%20data%20analysis/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    BigQuery for Data Analysis Quest
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../BigQuery%20for%20data%20warehousing/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    BigQuery for Data Warehousing Quest
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  <span class="md-ellipsis">
    Data Engineering Quest
  </span>
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  <span class="md-ellipsis">
    Data Engineering Quest
  </span>
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#etl-processing-on-google-cloud-using-dataflow-and-bigquery" class="md-nav__link">
    <span class="md-ellipsis">
      ETL Processing on Google Cloud Using Dataflow and BigQuery
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#building-an-iot-analytics-pipline-on-google-cloud" class="md-nav__link">
    <span class="md-ellipsis">
      Building an IoT Analytics Pipline on Google Cloud
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#cloud-composer-copying-bigquery-tables-across-different-locations" class="md-nav__link">
    <span class="md-ellipsis">
      Cloud Composer: Copying BigQuery Tables Across Different Locations
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#creating-a-data-transform-pipeline-with-cloud-dataprep" class="md-nav__link">
    <span class="md-ellipsis">
      Creating a Data Transform Pipeline with Cloud Dataprep
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#predict-housing-prices-with-tensorflow-and-ai-platform" class="md-nav__link">
    <span class="md-ellipsis">
      Predict Housing Prices with Tensorflow and AI platform
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#predict-visitor-purchases-with-a-classification-model" class="md-nav__link">
    <span class="md-ellipsis">
      Predict Visitor Purchases with a Classification model
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Machine%20learning%20APIs/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Integrate Machine Learning APIs Quest
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_6" >
        
          
          <label class="md-nav__link" for="__nav_6" id="__nav_6_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Jobs and Roles
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_6_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_6">
            <span class="md-nav__icon md-icon"></span>
            Jobs and Roles
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Jobs%20and%20Roles/data_engineer_role_sumathi_team/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Conversation with chapter lead data engineer
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Jobs%20and%20Roles/junior_data_engineer_at_woolies01/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Junior data engineer at woolies01
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_6_3" >
        
          
          <label class="md-nav__link" for="__nav_6_3" id="__nav_6_3_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Interview prep
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_6_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_6_3">
            <span class="md-nav__icon md-icon"></span>
            Interview prep
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Jobs%20and%20Roles/interview_prep/01_overview/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Data Engineering Interview Prep
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Jobs%20and%20Roles/interview_prep/_flashcard_template/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Flashcard template
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Jobs%20and%20Roles/interview_prep/bigO/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    BigO Notation
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Jobs%20and%20Roles/interview_prep/bubble_sort/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Bubble sort
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Jobs%20and%20Roles/interview_prep/flashcard_20231215/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Flashcard 20231215
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Jobs%20and%20Roles/interview_prep/flashcard_20231216/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Flashcard 20231216
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Jobs%20and%20Roles/interview_prep/flashcard_20240110/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Flashcard template
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Jobs%20and%20Roles/interview_prep/python02_sorting_and_searching/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Searching and sorting algorithms in python
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Jobs%20and%20Roles/interview_prep/python03_recursion/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Recursion
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Jobs%20and%20Roles/interview_prep/python04_hashtables/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Hashtables
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Jobs%20and%20Roles/interview_prep/python05_blooms/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Bloom filters
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Jobs%20and%20Roles/interview_prep/python06_graphs/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Graphing Algorithms
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Jobs%20and%20Roles/interview_prep/python_codewars/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Python Codewars problems
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Jobs%20and%20Roles/interview_prep/python_leetcode/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Leetcode problems solved with Python
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_7" >
        
          
          <label class="md-nav__link" for="__nav_7" id="__nav_7_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Linux
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_7_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_7">
            <span class="md-nav__icon md-icon"></span>
            Linux
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_7_1" >
        
          
          <label class="md-nav__link" for="__nav_7_1" id="__nav_7_1_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Data Analytics at the terminal
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_7_1_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_7_1">
            <span class="md-nav__icon md-icon"></span>
            Data Analytics at the terminal
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_7_1_1" >
        
          
          <label class="md-nav__link" for="__nav_7_1_1" id="__nav_7_1_1_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Crash Course
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_7_1_1_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_7_1_1">
            <span class="md-nav__icon md-icon"></span>
            Crash Course
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Linux/Data%20Analytics%20at%20the%20terminal/Crash%20Course/00_introduction/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Introduction and Motivation
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Linux/Data%20Analytics%20at%20the%20terminal/Crash%20Course/01_fundamental_bash_commands/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Fundamental Bash Commands
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Linux/Data%20Analytics%20at%20the%20terminal/Crash%20Course/02_expanding_the_fundamentals/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Expanding the fundamentals for Data Analysis
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Linux/Data%20Analytics%20at%20the%20terminal/Crash%20Course/03_downloading_files/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Downloading files with Bash
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Linux/Data%20Analytics%20at%20the%20terminal/Crash%20Course/04_working_with_text_files/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Working with and manipulating text files
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Linux/Data%20Analytics%20at%20the%20terminal/Crash%20Course/05_common_text_file_cleaning/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    BONUS - Common text file cleaning operations
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Linux/Data%20Analytics%20at%20the%20terminal/Crash%20Course/06_toolkit_setup/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Setup data tools
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Linux/Data%20Analytics%20at%20the%20terminal/Crash%20Course/07_csvkit_a_brief_detour/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    csvkit - a brief introduction
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Linux/Data%20Analytics%20at%20the%20terminal/Crash%20Course/08_getting_data_into_sqlite/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    08 getting data into sqlite
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Linux/Data%20Analytics%20at%20the%20terminal/Crash%20Course/09_interacting_with_sqlite/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Interacting with SQLite databases
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Linux/Data%20Analytics%20at%20the%20terminal/Crash%20Course/11_common_cleaning_tasks_in_sql/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Common data cleaning and transforming tasks in SQL
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Linux/Data%20Analytics%20at%20the%20terminal/Crash%20Course/12_replicating_common_spreadsheet_tasks_in_sql/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Replicating common spreadsheet tasks in SQL
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Linux/Data%20Analytics%20at%20the%20terminal/Crash%20Course/13_building_a_bash_script/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Building a pipeline as a bash script
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Linux/Data%20Analytics%20at%20the%20terminal/Crash%20Course/50_addditional_resources/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Additional resources
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_7_1_2" >
        
          
          <label class="md-nav__link" for="__nav_7_1_2" id="__nav_7_1_2_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Deepnote Notebooks
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_7_1_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_7_1_2">
            <span class="md-nav__icon md-icon"></span>
            Deepnote Notebooks
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Linux/Data%20Analytics%20at%20the%20terminal/Deepnote%20Notebooks/00_intro_to_data_analytics_at_terminal/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Environment setup
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Linux/Data%20Analytics%20at%20the%20terminal/Deepnote%20Notebooks/01_poking_around/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Exploring terminal functionality for interacting with data
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Linux/Data%20Analytics%20at%20the%20terminal/Deepnote%20Notebooks/02_grep_in_depth/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    GREP basics
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Linux/Data%20Analytics%20at%20the%20terminal/Deepnote%20Notebooks/05_becoming%20familiar%20with%20the%20data/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Getting a feel for the data
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Linux/Data%20Analytics%20at%20the%20terminal/Deepnote%20Notebooks/06_saving_data_to_sqlite/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Saving data to SQLite at the terminal
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Linux/Data%20Analytics%20at%20the%20terminal/Deepnote%20Notebooks/utilities%20available/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    CSV and SQLite tools overview
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_8" >
        
          
          <label class="md-nav__link" for="__nav_8" id="__nav_8_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Projects
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_8_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_8">
            <span class="md-nav__icon md-icon"></span>
            Projects
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_8_1" >
        
          
          <label class="md-nav__link" for="__nav_8_1" id="__nav_8_1_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Bitcoin Price Dashboard
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_8_1_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_8_1">
            <span class="md-nav__icon md-icon"></span>
            Bitcoin Price Dashboard
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Projects/Bitcoin%20Price%20Dashboard/01%20-%20summary/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Bitcoin Dashboard Project Details
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Projects/Bitcoin%20Price%20Dashboard/02%20-%20Cloud%20Function%20Code/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Bitcoin dashboard Cloud Function code
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Projects/Bitcoin%20Price%20Dashboard/03%20-%20Google%20Cloud%20Scheduler/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Scheduling and Monitoring
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Projects/Bitcoin%20Price%20Dashboard/04%20-%20Raw%20data%20transformation/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Bitcoin Data Transformation
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Projects/Bitcoin%20Price%20Dashboard/05%20-%20Project%20Visualisation/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Bitcoin project visualisation
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_8_2" >
        
          
          <label class="md-nav__link" for="__nav_8_2" id="__nav_8_2_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    fivethirtyeight data to BigQuery
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_8_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_8_2">
            <span class="md-nav__icon md-icon"></span>
            fivethirtyeight data to BigQuery
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Projects/fivethirtyeight%20data%20to%20BigQuery/01%20-%20summary/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Project details
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Projects/fivethirtyeight%20data%20to%20BigQuery/02%20-%20airflow%20setup/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Airflow server setup
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Projects/fivethirtyeight%20data%20to%20BigQuery/02b%20-%20DAG%20screenshots/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Airflow screenshots
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Projects/fivethirtyeight%20data%20to%20BigQuery/03%20-%20The%20DAG/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    fivethirtyeight DAG
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Projects/fivethirtyeight%20data%20to%20BigQuery/04%20-%20Project%20Visualisations/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Project visualisations
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_9" >
        
          
          <label class="md-nav__link" for="__nav_9" id="__nav_9_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Python
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_9_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_9">
            <span class="md-nav__icon md-icon"></span>
            Python
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Python/Apache%20Airflow/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Apache Airflow
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_9_2" >
        
          
          <label class="md-nav__link" for="__nav_9_2" id="__nav_9_2_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Data Engineering with python
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_9_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_9_2">
            <span class="md-nav__icon md-icon"></span>
            Data Engineering with python
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Python/Data%20Engineering%20with%20python/Chapter%201/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Chapter 1: What is data engineering
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Python/Data%20Engineering%20with%20python/Chapter%202%20-%20Notebook/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Chapter 2 - Notebook
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Python/Data%20Engineering%20with%20python/Chapter%202/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Chapter 2: Building Our Data Engineering Infrastructure
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Python/Data%20Engineering%20with%20python/Chapter%203%20-%20Notebook/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Chapter 3   Notebook
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Python/Data%20Engineering%20with%20python/Chapter%203/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Chapter 3: Reading and writing files
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Python/Data%20Engineering%20with%20python/Chapter%204%20-%20Notebook2/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Chapter 4 - Notebook
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Python/Data%20Engineering%20with%20python/Chapter%204/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Chapter 4: Working with Databases
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Python/Data%20Engineering%20with%20python/misc/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Misc
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_9_3" >
        
          
          <label class="md-nav__link" for="__nav_9_3" id="__nav_9_3_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Google Colab
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_9_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_9_3">
            <span class="md-nav__icon md-icon"></span>
            Google Colab
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Python/Google%20Colab/Converting_video_types_on_Google_Colab/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Converting between video types
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Python/Google%20Colab/Domo_Card_backup/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Backup of Domo Cards
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_9_3_3" >
        
          
          <label class="md-nav__link" for="__nav_9_3_3" id="__nav_9_3_3_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Intro to Google Colab Notebooks
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_9_3_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_9_3_3">
            <span class="md-nav__icon md-icon"></span>
            Intro to Google Colab Notebooks
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Python/Google%20Colab/Intro%20to%20Google%20Colab%20Notebooks/00_intro_to_colab/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    What is Google Colab
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Python/Google%20Colab/Intro%20to%20Google%20Colab%20Notebooks/01_using_google_drive_as_a_filesystem/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Using Google Drive as a filesystem in Google Colab
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Python/Google%20Colab/Intro%20to%20Google%20Colab%20Notebooks/02_reading_and_saving_to_google_sheets/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Reading from and saving to Google Sheets
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Python/Google%20Colab/Intro%20to%20Google%20Colab%20Notebooks/03_pulling_data_from_Adobe_analytics/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Accessing Adobe Analytics data through the API
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Python/Google%20Colab/Intro%20to%20Google%20Colab%20Notebooks/04_querying_BigQuery/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Query BigQuery from within Google Colab
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_9_4" >
        
          
          <label class="md-nav__link" for="__nav_9_4" id="__nav_9_4_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Pycon US 2021
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_9_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_9_4">
            <span class="md-nav__icon md-icon"></span>
            Pycon US 2021
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Python/Pycon%20US%202021/01%20keynote/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Keynote: Robert Erdmann
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Python/Pycon%20US%202021/02%20creating%20extensible%20workflows/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Creating extensible workflows
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Python/Pycon%20US%202021/03%20using%20papermill/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    What we learned from Papermill to operationalize notebooks
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Python/Pycon%20US%202021/04%20documentation%20for%20developers/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Writing Good Documentation for Developers
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Python/Pycon%20US%202021/07%20Google%20Serverless%20Application%20Architecture/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Google: Serverless Application Architecture
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Python/Pycon%20US%202021/08%20Build%20slack%20apps%20fast%20in%20python/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Build Slack apps fast in Python
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_10" >
        
          
          <label class="md-nav__link" for="__nav_10" id="__nav_10_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Resources
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_10_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_10">
            <span class="md-nav__icon md-icon"></span>
            Resources
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Resources/code_snippets/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Code snippets
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Resources/data_engineering_through_osmosis/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Data Engineering through osmosis
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Resources/links/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Links
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Resources/project_ideas/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Project ideas
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Resources/videos/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Videos
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#etl-processing-on-google-cloud-using-dataflow-and-bigquery" class="md-nav__link">
    <span class="md-ellipsis">
      ETL Processing on Google Cloud Using Dataflow and BigQuery
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#building-an-iot-analytics-pipline-on-google-cloud" class="md-nav__link">
    <span class="md-ellipsis">
      Building an IoT Analytics Pipline on Google Cloud
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#cloud-composer-copying-bigquery-tables-across-different-locations" class="md-nav__link">
    <span class="md-ellipsis">
      Cloud Composer: Copying BigQuery Tables Across Different Locations
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#creating-a-data-transform-pipeline-with-cloud-dataprep" class="md-nav__link">
    <span class="md-ellipsis">
      Creating a Data Transform Pipeline with Cloud Dataprep
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#predict-housing-prices-with-tensorflow-and-ai-platform" class="md-nav__link">
    <span class="md-ellipsis">
      Predict Housing Prices with Tensorflow and AI platform
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#predict-visitor-purchases-with-a-classification-model" class="md-nav__link">
    <span class="md-ellipsis">
      Predict Visitor Purchases with a Classification model
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  


<h1 id="data-engineering-quest">Data Engineering Quest</h1>
<h2 id="etl-processing-on-google-cloud-using-dataflow-and-bigquery">ETL Processing on Google Cloud Using Dataflow and BigQuery</h2>
<p><a href="https://marquin-space-object-storage-01.sgp1.cdn.digitaloceanspaces.com/web-resources/htmls/ETL%20Processing%20on%20Google%20Cloud%20Using%20Dataflow%20and%20BigQuery%20_%20Qwiklabs%20%282021-04-10%206_46_25%20am%29.html">ETL Processing using Dataflow and BigQuery</a></p>
<p>data_ingestion.py</p>
<pre><code class="language-python"># Copyright 2017 Google Inc.
#
# Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#      http://www.apache.org/licenses/LICENSE-2.0#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an &quot;AS IS&quot; BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
&quot;&quot;&quot;`data_ingestion.py` is a Dataflow pipeline which reads a file and writes its
contents to a BigQuery table.
This example does not do any transformation on the data.
&quot;&quot;&quot;


import argparse
import logging
import re
import apache_beam as beam
from apache_beam.options.pipeline_options import PipelineOptions


class DataIngestion:
    &quot;&quot;&quot;A helper class which contains the logic to translate the file into
    a format BigQuery will accept.&quot;&quot;&quot;
    def parse_method(self, string_input):
        &quot;&quot;&quot;This method translates a single line of comma separated values to a
        dictionary which can be loaded into BigQuery.

        Args:
            string_input: A comma separated list of values in the form of
                state_abbreviation,gender,year,name,count_of_babies,dataset_created_date
                Example string_input: KS,F,1923,Dorothy,654,11/28/2016

        Returns:
            A dict mapping BigQuery column names as keys to the corresponding value
            parsed from string_input. In this example, the data is not transformed, and
            remains in the same format as the CSV.
            example output:
            {
                'state': 'KS',
                'gender': 'F',
                'year': '1923',
                'name': 'Dorothy',
                'number': '654',
                'created_date': '11/28/2016'
            }
         &quot;&quot;&quot;
        # Strip out carriage return, newline and quote characters.
        values = re.split(&quot;,&quot;,
                          re.sub('\r\n', '', re.sub('&quot;', '', string_input)))
        row = dict(
            zip(('state', 'gender', 'year', 'name', 'number', 'created_date'),
                values))
        return row


def run(argv=None):
    &quot;&quot;&quot;The main function which creates the pipeline and runs it.&quot;&quot;&quot;

    parser = argparse.ArgumentParser()

    # Here we add some specific command line arguments we expect.
    # Specifically we have the input file to read and the output table to write.
    # This is the final stage of the pipeline, where we define the destination
    # of the data. In this case we are writing to BigQuery.
    parser.add_argument(
        '--input',
        dest='input',
        required=False,
        help='Input file to read. This can be a local file or '
        'a file in a Google Storage Bucket.',
        # This example file contains a total of only 10 lines.
        # Useful for developing on a small set of data.
        default='gs://spls/gsp290/data_files/head_usa_names.csv')

    # This defaults to the lake dataset in your BigQuery project. You'll have
    # to create the lake dataset yourself using this command:
    # bq mk lake
    parser.add_argument('--output',
                        dest='output',
                        required=False,
                        help='Output BQ table to write results to.',
                        default='lake.usa_names')

    # Parse arguments from the command line.
    known_args, pipeline_args = parser.parse_known_args(argv)

    # DataIngestion is a class we built in this script to hold the logic for
    # transforming the file into a BigQuery table.
    data_ingestion = DataIngestion()

    # Initiate the pipeline using the pipeline arguments passed in from the
    # command line. This includes information such as the project ID and
    # where Dataflow should store temp files.
    p = beam.Pipeline(options=PipelineOptions(pipeline_args))

    (p
     # Read the file. This is the source of the pipeline. All further
     # processing starts with lines read from the file. We use the input
     # argument from the command line. We also skip the first line which is a
     # header row.
     | 'Read from a File' &gt;&gt; beam.io.ReadFromText(known_args.input,
                                                  skip_header_lines=1)
     # This stage of the pipeline translates from a CSV file single row
     # input as a string, to a dictionary object consumable by BigQuery.
     # It refers to a function we have written. This function will
     # be run in parallel on different workers using input from the
     # previous stage of the pipeline.
     | 'String To BigQuery Row' &gt;&gt;
     beam.Map(lambda s: data_ingestion.parse_method(s))
     | 'Write to BigQuery' &gt;&gt; beam.io.Write(
         beam.io.BigQuerySink(
             # The table name is a required argument for the BigQuery sink.
             # In this case we use the value passed in from the command line.
             known_args.output,
             # Here we use the simplest way of defining a schema:
             # fieldName:fieldType
             schema='state:STRING,gender:STRING,year:STRING,name:STRING,'
             'number:STRING,created_date:STRING',
             # Creates the table in BigQuery if it does not yet exist.
             create_disposition=beam.io.BigQueryDisposition.CREATE_IF_NEEDED,
             # Deletes all data in the BigQuery table before writing.
             write_disposition=beam.io.BigQueryDisposition.WRITE_TRUNCATE)))
    p.run().wait_until_finish()


if __name__ == '__main__':
    logging.getLogger().setLevel(logging.INFO)
    run()
</code></pre>
<p>run the script</p>
<pre><code class="language-bash">python dataflow_python_examples/data_ingestion.py --project=$PROJECT --region=us-central1 --runner=DataflowRunner --staging_location=gs://$PROJECT/test --temp_location gs://$PROJECT/test --input gs://$PROJECT/data_files/head_usa_names.csv --save_main_session
</code></pre>
<p>data_transformation.py</p>
<pre><code class="language-python"># Copyright 2017 Google Inc.
#
# Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#      http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an &quot;AS IS&quot; BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

&quot;&quot;&quot; data_transformation.py is a Dataflow pipeline which reads a file and writes
its contents to a BigQuery table.

This example reads a json schema of the intended output into BigQuery,
and transforms the date data to match the format BigQuery expects.
&quot;&quot;&quot;


import argparse
import csv
import logging
import os

import apache_beam as beam
from apache_beam.options.pipeline_options import PipelineOptions
from apache_beam.io.gcp.bigquery_tools import parse_table_schema_from_json


class DataTransformation:
    &quot;&quot;&quot;A helper class which contains the logic to translate the file into a
  format BigQuery will accept.&quot;&quot;&quot;

    def __init__(self):
        dir_path = os.path.dirname(os.path.realpath(__file__))
        self.schema_str = ''
        # Here we read the output schema from a json file.  This is used to specify the types
        # of data we are writing to BigQuery.
        schema_file = os.path.join(dir_path, 'resources', 'usa_names_year_as_date.json')
        with open(schema_file) \
                as f:
            data = f.read()
            # Wrapping the schema in fields is required for the BigQuery API.
            self.schema_str = '{&quot;fields&quot;: ' + data + '}'

    def parse_method(self, string_input):
        &quot;&quot;&quot;This method translates a single line of comma separated values to a
    dictionary which can be loaded into BigQuery.

        Args:
            string_input: A comma separated list of values in the form of
            state_abbreviation,gender,year,name,count_of_babies,dataset_created_date
                example string_input: KS,F,1923,Dorothy,654,11/28/2016

        Returns:
            A dict mapping BigQuery column names as keys to the corresponding value
            parsed from string_input.  In this example, the data is not transformed, and
            remains in the same format as the CSV.  There are no date format transformations.

                example output:
                      {'state': 'KS',
                       'gender': 'F',
                       'year': '1923-01-01', &lt;- This is the BigQuery date format.
                       'name': 'Dorothy',
                       'number': '654',
                       'created_date': '11/28/2016'
                       }
        &quot;&quot;&quot;
        # Strip out return characters and quote characters.
        schema = parse_table_schema_from_json(self.schema_str)

        field_map = [f for f in schema.fields]

        # Use a CSV Reader which can handle quoted strings etc.
        reader = csv.reader(string_input.split('\n'))
        for csv_row in reader:
            # Our source data only contains year, so default January 1st as the
            # month and day.
            month = '01'
            day = '01'
            # The year comes from our source data.
            year = csv_row[2]

            row = {}
            i = 0
            # Iterate over the values from our csv file, applying any transformation logic.
            for value in csv_row:
                # If the schema indicates this field is a date format, we must
                # transform the date from the source data into a format that
                # BigQuery can understand.
                if field_map[i].type == 'DATE':
                    # Format the date to YYYY-MM-DD format which BigQuery
                    # accepts.
                    value = '-'.join((year, month, day))

                row[field_map[i].name] = value
                i += 1

            return row


def run(argv=None):
    &quot;&quot;&quot;The main function which creates the pipeline and runs it.&quot;&quot;&quot;
    parser = argparse.ArgumentParser()
    # Here we add some specific command line arguments we expect.   Specifically
    # we have the input file to load and the output table to write to.
    parser.add_argument(
        '--input', dest='input', required=False,
        help='Input file to read.  This can be a local file or '
             'a file in a Google Storage Bucket.',
        # This example file contains a total of only 10 lines.
        # It is useful for developing on a small set of data
        default='gs://spls/gsp290/data_files/head_usa_names.csv')
    # This defaults to the temp dataset in your BigQuery project.  You'll have
    # to create the temp dataset yourself using bq mk temp
    parser.add_argument('--output', dest='output', required=False,
                        help='Output BQ table to write results to.',
                        default='lake.usa_names_transformed')

    # Parse arguments from the command line.
    known_args, pipeline_args = parser.parse_known_args(argv)
    # DataTransformation is a class we built in this script to hold the logic for
    # transforming the file into a BigQuery table.
    data_ingestion = DataTransformation()

    # Initiate the pipeline using the pipeline arguments passed in from the
    # command line.  This includes information like where Dataflow should
    # store temp files, and what the project id is.
    p = beam.Pipeline(options=PipelineOptions(pipeline_args))
    schema = parse_table_schema_from_json(data_ingestion.schema_str)

    (p
     # Read the file.  This is the source of the pipeline.  All further
     # processing starts with lines read from the file.  We use the input
     # argument from the command line.  We also skip the first line which is a
     # header row.
     | 'Read From Text' &gt;&gt; beam.io.ReadFromText(known_args.input,
                                                skip_header_lines=1)
     # This stage of the pipeline translates from a CSV file single row
     # input as a string, to a dictionary object consumable by BigQuery.
     # It refers to a function we have written.  This function will
     # be run in parallel on different workers using input from the
     # previous stage of the pipeline.
     | 'String to BigQuery Row' &gt;&gt; beam.Map(lambda s:
                                            data_ingestion.parse_method(s))
     | 'Write to BigQuery' &gt;&gt; beam.io.Write(
        beam.io.BigQuerySink(
            # The table name is a required argument for the BigQuery sink.
            # In this case we use the value passed in from the command line.
            known_args.output,
            # Here we use the JSON schema read in from a JSON file.
            # Specifying the schema allows the API to create the table correctly if it does not yet exist.
            schema=schema,
            # Creates the table in BigQuery if it does not yet exist.
            create_disposition=beam.io.BigQueryDisposition.CREATE_IF_NEEDED,
            # Deletes all data in the BigQuery table before writing.
            write_disposition=beam.io.BigQueryDisposition.WRITE_TRUNCATE)))
    p.run().wait_until_finish()


if __name__ == '__main__':
    logging.getLogger().setLevel(logging.INFO)
    run()
</code></pre>
<p>data_enrichment.py</p>
<pre><code class="language-python"># Copyright 2017 Google Inc.
#
# Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at#
#      http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software# distributed under the License is distributed on an &quot;AS IS&quot; BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and# limitations under the License.
&quot;&quot;&quot; data_enrichment.py demonstrates a Dataflow pipeline which reads a file and
 writes its contents to a BigQuery table.  Along the way, data from BigQuery is read in as a side input and joined in with the primary data from the file.
&quot;&quot;&quot;
import argparse
import csvimport logging
import osimport sys

import apache_beam as beam
from apache_beam.io.gcp import bigquery
from apache_beam.io.gcp.bigquery import parse_table_schema_from_json
from apache_beam.options.pipeline_options import PipelineOptionsfrom apache_beam.pvalue import AsDict


class DataIngestion(object):
    &quot;&quot;&quot;A helper class which contains the logic to translate the file into a
  format BigQuery will accept.&quot;&quot;&quot;

    def __init__(self):
        dir_path = os.path.dirname(os.path.realpath(__file__))
        self.schema_str = ''
        # This is the schema of the destination table in BigQuery.
        schema_file = os.path.join(dir_path, 'resources', 'usa_names_with_full_state_name.json')
        with open(schema_file) \
                as f:
            data = f.read()
            # Wrapping the schema in fields is required for the BigQuery API.
            self.schema_str = '{&quot;fields&quot;: ' + data + '}'

    def parse_method(self, string_input):
        &quot;&quot;&quot;This method translates a single line of comma separated values to a
    dictionary which can be loaded into BigQuery.

        Args:
            string_input: A comma separated list of values in the form of
            state_abbreviation,gender,year,name,count_of_babies,dataset_created_date
                example string_input: KS,F,1923,Dorothy,654,11/28/2016

        Returns:
            A dict mapping BigQuery column names as keys to the corresponding value
            parsed from string_input.  In this example, the data is not transformed, and
            remains in the same format as the CSV.  There are no date format transformations.

                example output:
                      {'state': 'KS',
                       'gender': 'F',
                       'year': '1923-01-01', &lt;- This is the BigQuery date format.
                       'name': 'Dorothy',
                       'number': '654',
                       'created_date': '11/28/2016'
                       }

     &quot;&quot;&quot;
        # Strip out return characters and quote characters.
        schema = bigquery.parse_table_schema_from_json(self.schema_str)

        field_map = [f for f in schema.fields]

        # Use a CSV Reader which can handle quoted strings etc.
        reader = csv.reader(string_input.split('\n'))
        for csv_row in reader:
            if (sys.version_info.major &lt; 3.0):
                values = [x.decode('utf8') for x in csv_row]
            else:
                values = csv_row
            # Our source data only contains year, so default January 1st as the
            # month and day.
            month = '01'
            day = '01'
            # The year comes from our source data.
            year = values[2]
            row = {}
            i = 0
            # Iterate over the values from our csv file, applying any transformation logic.
            for value in values:
                # If the schema indicates this field is a date format, we must
                # transform the date from the source data into a format that
                # BigQuery can understand.
                if field_map[i].type == 'DATE':
                    # Format the date to YYYY-MM-DD format which BigQuery
                    # accepts.
                    value = '-'.join((year, month, day))

                row[field_map[i].name] = value
                i += 1

            return row


def run(argv=None):
    &quot;&quot;&quot;The main function which creates the pipeline and runs it.&quot;&quot;&quot;
    parser = argparse.ArgumentParser()
    # Here we add some specific command line arguments we expect.   Specifically
    # we have the input file to load and the output table to write to.
    parser.add_argument(
        '--input', dest='input', required=False,
        help='Input file to read.  This can be a local file or '
             'a file in a Google Storage Bucket.',
        # This example file contains a total of only 10 lines.
        # Useful for quickly debugging on a small set of data
        default='gs://spls/gsp290/data_files/head_usa_names.csv')
    # The output defaults to the lake dataset in your BigQuery project.  You'll have
    # to create the lake dataset yourself using this command:
    # bq mk lake
    parser.add_argument('--output', dest='output', required=False,
                        help='Output BQ table to write results to.',
                        default='lake.usa_names_enriched')

    # Parse arguments from the command line.
    known_args, pipeline_args = parser.parse_known_args(argv)

    # DataIngestion is a class we built in this script to hold the logic for
    # transforming the file into a BigQuery table.
    data_ingestion = DataIngestion()

    # Initiate the pipeline using the pipeline arguments passed in from the
    # command line.  This includes information like where Dataflow should store
    #  temp files, and what the project id is
    p = beam.Pipeline(options=PipelineOptions(pipeline_args))
    schema = parse_table_schema_from_json(data_ingestion.schema_str)

    # This function adds in a full state name by looking up the
    # full name in the short_to_long_name_map.  The short_to_long_name_map
    # comes from a read from BigQuery in the next few lines
    def add_full_state_name(row, short_to_long_name_map):
        row['state_full_name'] = short_to_long_name_map[row['state']]
        return row

    # This is a second source of data.  The source is from BigQuery.
    # This will come into our pipeline a side input.

    read_query = &quot;&quot;&quot;
    SELECT
    name as state_name,
    abbreviation as state_abbreviation
    FROM
    `qwiklabs-resources.python_dataflow_example.state_abbreviations`&quot;&quot;&quot;

    state_abbreviations = (
        p
        | 'Read from BigQuery' &gt;&gt; beam.io.Read(
            beam.io.BigQuerySource(query=read_query, use_standard_sql=True))
        # We must create a python tuple of key to value pairs here in order to
        # use the data as a side input.  Dataflow will use the keys to distribute the
        # work to the correct worker.
        | 'Abbreviation to Full Name' &gt;&gt; beam.Map(
            lambda row: (row['state_abbreviation'], row['state_name'])))

    (p
     # Read the file.  This is the source of the pipeline.  All further
     # processing starts with lines read from the file.  We use the input
     # argument from the command line.  We also skip the first line which is
     # a header row.
     | 'Read From Text' &gt;&gt; beam.io.ReadFromText(known_args.input,
                                                skip_header_lines=1)
     # Translates from the raw string data in the CSV to a dictionary.
     # The dictionary is a keyed by column names with the values being the values
     # we want to store in BigQuery.
     | 'String to BigQuery Row' &gt;&gt; beam.Map(lambda s:
                                            data_ingestion.parse_method(s))
     # Here we pass in a side input, which is data that comes from outside our
     # CSV source.  The side input contains a map of states to their full name.
     | 'Join Data' &gt;&gt; beam.Map(add_full_state_name, AsDict(
        state_abbreviations))
     # This is the final stage of the pipeline, where we define the destination
     #  of the data.  In this case we are writing to BigQuery.
     | 'Write to BigQuery' &gt;&gt; beam.io.Write(
        beam.io.BigQuerySink(
            # The table name is a required argument for the BigQuery sink.
            # In this case we use the value passed in from the command line.
            known_args.output,
            # Here we use the JSON schema read in from a JSON file.
            # Specifying the schema allows the API to create the table correctly if it does not yet exist.
            schema=schema,
            # Creates the table in BigQuery if it does not yet exist.
            create_disposition=beam.io.BigQueryDisposition.CREATE_IF_NEEDED,
            # Deletes all data in the BigQuery table before writing.
            write_disposition=beam.io.BigQueryDisposition.WRITE_TRUNCATE)))
    p.run().wait_until_finish()


if __name__ == '__main__':
    logging.getLogger().setLevel(logging.INFO)
    run()
</code></pre>
<p>run script</p>
<pre><code class="language-bash">python dataflow_python_examples/data_enrichment.py --project=$PROJECT --region=us-central1 --runner=DataflowRunner --staging_location=gs://$PROJECT/test --temp_location gs://$PROJECT/test --input gs://$PROJECT/data_files/head_usa_names.csv --save_main_session
</code></pre>
<p>data_lake_to_mart.py</p>
<pre><code class="language-python">

</code></pre>
<p>run script</p>
<pre><code class="language-bash">python dataflow_python_examples/data_lake_to_mart.py --worker_disk_type=&quot;compute.googleapis.com/projects//zones//diskTypes/pd-ssd&quot; --max_num_workers=4 --project=$PROJECT --runner=DataflowRunner --staging_location=gs://$PROJECT/test --temp_location gs://$PROJECT/test --save_main_session --region=us-central1
</code></pre>
<hr />
<h2 id="building-an-iot-analytics-pipline-on-google-cloud">Building an IoT Analytics Pipline on Google Cloud</h2>
<p><a href="https://marquin-space-object-storage-01.sgp1.cdn.digitaloceanspaces.com/web-resources/htmls/Building%20an%20IoT%20Analytics%20Pipeline%20on%20Google%20Cloud%20_%20Qwiklabs%20%282021-04-21%204_15_02%20pm%29.html">Building an IoT Analytics Pipeline on Google Cloud Qwiklab</a></p>
<h2 id="cloud-composer-copying-bigquery-tables-across-different-locations">Cloud Composer: Copying BigQuery Tables Across Different Locations</h2>
<p><a href="https://marquin-space-object-storage-01.sgp1.cdn.digitaloceanspaces.com/web-resources/htmls/Cloud%20Composer_%20Copying%20BigQuery%20Tables%20Across%20Different%20Locations%20_%20Qwiklabs%20%282021-04-21%204_14_07%20pm%29.html">Cloud Composer: Copying BigQuery Tables Across Different Locations Qwiklab</a></p>
<p>bq_copy_across_locations.py</p>
<p><a href="https://github.com/GoogleCloudPlatform/python-docs-samples/blob/master/composer/workflows/bq_copy_across_locations.py">location</a> </p>
<pre><code class="language-python"># Copyright 2018 Google LLC
#
# Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     https://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an &quot;AS IS&quot; BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

&quot;&quot;&quot;Example Airflow DAG that performs an export from BQ tables listed in
config file to GCS, copies GCS objects across locations (e.g., from US to
EU) then imports from GCS to BQ. The DAG imports the gcs_to_gcs operator
from plugins and dynamically builds the tasks based on the list of tables.
Lastly, the DAG defines a specific application logger to generate logs.
This DAG relies on three Airflow variables
(https://airflow.apache.org/concepts.html#variables):
* table_list_file_path - CSV file listing source and target tables, including
Datasets.
* gcs_source_bucket - Google Cloud Storage bucket to use for exporting
BigQuery tables in source.
* gcs_dest_bucket - Google Cloud Storage bucket to use for importing
BigQuery tables in destination.
See https://cloud.google.com/storage/docs/creating-buckets for creating a
bucket.
&quot;&quot;&quot;

# --------------------------------------------------------------------------------
# Load The Dependencies
# --------------------------------------------------------------------------------

import csv
import datetime
import io
import logging

from airflow import models
from airflow.contrib.operators import bigquery_to_gcs
from airflow.contrib.operators import gcs_to_bq
from airflow.contrib.operators import gcs_to_gcs
from airflow.operators import dummy_operator


# --------------------------------------------------------------------------------
# Set default arguments
# --------------------------------------------------------------------------------

yesterday = datetime.datetime.now() - datetime.timedelta(days=1)

default_args = {
    'owner': 'airflow',
    'start_date': yesterday,
    'depends_on_past': False,
    'email': [''],
    'email_on_failure': False,
    'email_on_retry': False,
    'retries': 1,
    'retry_delay': datetime.timedelta(minutes=5),
}

# --------------------------------------------------------------------------------
# Set variables
# --------------------------------------------------------------------------------

# 'table_list_file_path': This variable will contain the location of the master
# file.
table_list_file_path = models.Variable.get('table_list_file_path')

# Source Bucket
source_bucket = models.Variable.get('gcs_source_bucket')

# Destination Bucket
dest_bucket = models.Variable.get('gcs_dest_bucket')

# --------------------------------------------------------------------------------
# Set GCP logging
# --------------------------------------------------------------------------------

logger = logging.getLogger('bq_copy_us_to_eu_01')

# --------------------------------------------------------------------------------
# Functions
# --------------------------------------------------------------------------------


def read_table_list(table_list_file):
    &quot;&quot;&quot;
    Reads the table list file that will help in creating Airflow tasks in
    the DAG dynamically.
    :param table_list_file: (String) The file location of the table list file,
    e.g. '/home/airflow/framework/table_list.csv'
    :return table_list: (List) List of tuples containing the source and
    target tables.
    &quot;&quot;&quot;
    table_list = []
    logger.info('Reading table_list_file from : %s' % str(table_list_file))
    try:
        with io.open(table_list_file, 'rt', encoding='utf-8') as csv_file:
            csv_reader = csv.reader(csv_file)
            next(csv_reader)  # skip the headers
            for row in csv_reader:
                logger.info(row)
                table_tuple = {
                    'table_source': row[0],
                    'table_dest': row[1]
                }
                table_list.append(table_tuple)
            return table_list
    except IOError as e:
        logger.error('Error opening table_list_file %s: ' % str(
            table_list_file), e)


# --------------------------------------------------------------------------------
# Main DAG
# --------------------------------------------------------------------------------

# Define a DAG (directed acyclic graph) of tasks.
# Any task you create within the context manager is automatically added to the
# DAG object.
with models.DAG(
        'composer_sample_bq_copy_across_locations',
        default_args=default_args,
        schedule_interval=None) as dag:
    start = dummy_operator.DummyOperator(
        task_id='start',
        trigger_rule='all_success'
    )

    end = dummy_operator.DummyOperator(
        task_id='end',
        trigger_rule='all_success'
    )

    # Get the table list from master file
    all_records = read_table_list(table_list_file_path)

    # Loop over each record in the 'all_records' python list to build up
    # Airflow tasks
    for record in all_records:
        logger.info('Generating tasks to transfer table: {}'.format(record))

        table_source = record['table_source']
        table_dest = record['table_dest']

        BQ_to_GCS = bigquery_to_gcs.BigQueryToCloudStorageOperator(
            # Replace &quot;:&quot; with valid character for Airflow task
            task_id='{}_BQ_to_GCS'.format(table_source.replace(&quot;:&quot;, &quot;_&quot;)),
            source_project_dataset_table=table_source,
            destination_cloud_storage_uris=['{}-*.avro'.format(
                'gs://' + source_bucket + '/' + table_source)],
            export_format='AVRO'
        )

        GCS_to_GCS = gcs_to_gcs.GoogleCloudStorageToGoogleCloudStorageOperator(
            # Replace &quot;:&quot; with valid character for Airflow task
            task_id='{}_GCS_to_GCS'.format(table_source.replace(&quot;:&quot;, &quot;_&quot;)),
            source_bucket=source_bucket,
            source_object='{}-*.avro'.format(table_source),
            destination_bucket=dest_bucket,
            # destination_object='{}-*.avro'.format(table_dest)
        )

        GCS_to_BQ = gcs_to_bq.GoogleCloudStorageToBigQueryOperator(
            # Replace &quot;:&quot; with valid character for Airflow task
            task_id='{}_GCS_to_BQ'.format(table_dest.replace(&quot;:&quot;, &quot;_&quot;)),
            bucket=dest_bucket,
            source_objects=['{}-*.avro'.format(table_source)],
            destination_project_dataset_table=table_dest,
            source_format='AVRO',
            write_disposition='WRITE_TRUNCATE',
            autodetect=True
        )

        start &gt;&gt; BQ_to_GCS &gt;&gt; GCS_to_GCS &gt;&gt; GCS_to_BQ &gt;&gt; end
</code></pre>
<h2 id="creating-a-data-transform-pipeline-with-cloud-dataprep">Creating a Data Transform Pipeline with Cloud Dataprep</h2>
<p><a href="https://marquin-space-object-storage-01.sgp1.cdn.digitaloceanspaces.com/web-resources/htmls/Creating%20a%20Data%20Transformation%20Pipeline%20with%20Cloud%20Dataprep%20_%20Qwiklabs%20%282021-04-21%204_16_22%20pm%29.html">Creating a Data Transform Pipeline with Cloud Dataprep Qwiklab</a></p>
<h2 id="predict-housing-prices-with-tensorflow-and-ai-platform">Predict Housing Prices with Tensorflow and AI platform</h2>
<p><a href="https://marquin-space-object-storage-01.sgp1.cdn.digitaloceanspaces.com/web-resources/htmls/Predict%20Housing%20Prices%20with%20Tensorflow%20and%20AI%20Platform%20_%20Qwiklabs%20%282021-04-21%208_56_43%20am%29.html">Predict Housing Prices with Tensorflow and AI platform</a></p>
<h2 id="predict-visitor-purchases-with-a-classification-model">Predict Visitor Purchases with a Classification model</h2>
<p><a href="https://marquin-space-object-storage-01.sgp1.cdn.digitaloceanspaces.com/web-resources/htmls/Predict%20Visitor%20Purchases%20with%20a%20Classification%20Model%20in%20BQML%20_%20Qwiklabs%20%282021-04-21%204_58_25%20pm%29.html">Predict Visitor Purchases with a Classification model Qwiklab</a></p>












                
              </article>
            </div>
          
          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    <script id="__config" type="application/json">{"base": "../../..", "features": [], "search": "../../../assets/javascripts/workers/search.c011b7c0.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}}</script>
    
    
      <script src="../../../assets/javascripts/bundle.7389ff0e.min.js"></script>
      
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.7.2/highlight.min.js"></script>
      
        <script src="../../../javascripts/config.js"></script>
      
    
  </body>
</html>